---
# AI Datacenter Infrastructure Playbook
# This playbook configures GPU compute nodes, storage systems, and networking
# for high-performance AI/ML workloads

- name: Configure AI Compute Nodes
  hosts: gpu_nodes
  become: yes
  vars:
    cuda_version: "12.3"
    driver_version: "545.23.08"
    docker_version: "24.0.7"
    nvidia_container_toolkit_version: "1.14.3"
  
  tasks:
    - name: Update system packages
      apt:
        update_cache: yes
        upgrade: dist
        cache_valid_time: 3600
      when: ansible_os_family == "Debian"

    - name: Install required dependencies
      apt:
        name:
          - build-essential
          - linux-headers-{{ ansible_kernel }}
          - dkms
          - curl
          - wget
          - software-properties-common
        state: present

    - name: Add NVIDIA driver repository
      apt_repository:
        repo: ppa:graphics-drivers/ppa
        state: present

    - name: Install NVIDIA drivers
      apt:
        name: nvidia-driver-{{ driver_version.split('.')[0] }}
        state: present
      register: nvidia_driver

    - name: Reboot if NVIDIA driver was installed
      reboot:
        reboot_timeout: 600
      when: nvidia_driver.changed

    - name: Install CUDA toolkit
      block:
        - name: Download CUDA repository pin
          get_url:
            url: "https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin"
            dest: /etc/apt/preferences.d/cuda-repository-pin-600

        - name: Add CUDA repository key
          apt_key:
            url: "https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub"
            state: present

        - name: Add CUDA repository
          apt_repository:
            repo: "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ /"
            state: present

        - name: Install CUDA
          apt:
            name: cuda-{{ cuda_version }}
            state: present
            update_cache: yes

    - name: Configure CUDA environment variables
      lineinfile:
        path: /etc/environment
        line: "{{ item }}"
        create: yes
      loop:
        - 'PATH="/usr/local/cuda/bin:$PATH"'
        - 'LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"'

    - name: Install Docker
      block:
        - name: Add Docker GPG key
          apt_key:
            url: https://download.docker.com/linux/ubuntu/gpg
            state: present

        - name: Add Docker repository
          apt_repository:
            repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
            state: present

        - name: Install Docker Engine
          apt:
            name:
              - docker-ce={{ docker_version }}~3-0~ubuntu-{{ ansible_distribution_release }}
              - docker-ce-cli={{ docker_version }}~3-0~ubuntu-{{ ansible_distribution_release }}
              - containerd.io
            state: present
            update_cache: yes

    - name: Install NVIDIA Container Toolkit
      block:
        - name: Add NVIDIA Container Toolkit repository
          shell: |
            distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
            curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | apt-key add -
            curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

        - name: Install nvidia-container-toolkit
          apt:
            name: nvidia-container-toolkit={{ nvidia_container_toolkit_version }}-1
            state: present
            update_cache: yes

        - name: Configure Docker to use NVIDIA runtime
          copy:
            content: |
              {
                "runtimes": {
                  "nvidia": {
                    "path": "nvidia-container-runtime",
                    "runtimeArgs": []
                  }
                },
                "default-runtime": "nvidia"
              }
            dest: /etc/docker/daemon.json

        - name: Restart Docker service
          systemd:
            name: docker
            state: restarted
            enabled: yes

    - name: Configure system limits for AI workloads
      pam_limits:
        domain: '*'
        limit_type: "{{ item.type }}"
        limit_item: "{{ item.item }}"
        value: "{{ item.value }}"
      loop:
        - { type: 'soft', item: 'nofile', value: '1048576' }
        - { type: 'hard', item: 'nofile', value: '1048576' }
        - { type: 'soft', item: 'memlock', value: 'unlimited' }
        - { type: 'hard', item: 'memlock', value: 'unlimited' }

    - name: Configure kernel parameters
      sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        reload: yes
      loop:
        - { name: 'net.core.rmem_max', value: '268435456' }
        - { name: 'net.core.wmem_max', value: '268435456' }
        - { name: 'net.ipv4.tcp_rmem', value: '4096 87380 134217728' }
        - { name: 'net.ipv4.tcp_wmem', value: '4096 65536 134217728' }
        - { name: 'vm.swappiness', value: '10' }

- name: Configure High-Speed Storage
  hosts: storage_nodes
  become: yes
  vars:
    nfs_exports:
      - path: /data/datasets
        options: "*(rw,sync,no_subtree_check,no_root_squash)"
      - path: /data/models
        options: "*(rw,sync,no_subtree_check,no_root_squash)"
  
  tasks:
    - name: Install NFS server
      apt:
        name:
          - nfs-kernel-server
          - nfs-common
        state: present

    - name: Create storage directories
      file:
        path: "{{ item.path }}"
        state: directory
        mode: '0755'
      loop: "{{ nfs_exports }}"

    - name: Configure NFS exports
      lineinfile:
        path: /etc/exports
        line: "{{ item.path }} {{ item.options }}"
        create: yes
      loop: "{{ nfs_exports }}"
      notify: reload nfs

    - name: Optimize NFS performance
      lineinfile:
        path: /etc/nfs.conf
        regexp: "{{ item.regexp }}"
        line: "{{ item.line }}"
      loop:
        - { regexp: '^#?\s*threads=', line: 'threads=128' }
        - { regexp: '^#?\s*manage-gids=', line: 'manage-gids=yes' }
      notify: restart nfs

  handlers:
    - name: reload nfs
      systemd:
        name: nfs-server
        state: reloaded

    - name: restart nfs
      systemd:
        name: nfs-server
        state: restarted

- name: Configure High-Performance Networking
  hosts: all
  become: yes
  vars:
    rdma_enabled: true
    mtu_size: 9000
  
  tasks:
    - name: Install InfiniBand/RDMA packages
      apt:
        name:
          - infiniband-diags
          - ibverbs-utils
          - rdma-core
          - perftest
        state: present
      when: rdma_enabled

    - name: Load RDMA kernel modules
      modprobe:
        name: "{{ item }}"
        state: present
      loop:
        - ib_uverbs
        - rdma_ucm
        - ib_ipoib
      when: rdma_enabled

    - name: Configure jumbo frames
      lineinfile:
        path: /etc/network/interfaces.d/{{ ansible_default_ipv4.interface }}
        line: "    mtu {{ mtu_size }}"
        insertafter: "iface {{ ansible_default_ipv4.interface }}"
        create: yes
      when: mtu_size > 1500

    - name: Disable firewall for cluster network (production should use proper firewall rules)
      ufw:
        state: disabled

    - name: Install cluster monitoring tools
      apt:
        name:
          - prometheus-node-exporter
          - nvidia-dcgm
        state: present

- name: Install AI/ML Software Stack
  hosts: gpu_nodes
  become: yes
  
  tasks:
    - name: Install Python and pip
      apt:
        name:
          - python3
          - python3-pip
          - python3-venv
        state: present

    - name: Install common ML libraries
      pip:
        name:
          - torch
          - torchvision
          - torchaudio
          - transformers
          - accelerate
          - deepspeed
          - ninja
        extra_args: "--index-url https://download.pytorch.org/whl/cu121"
        state: present

    - name: Install Kubernetes tools (for orchestration)
      block:
        - name: Add Kubernetes repository key
          apt_key:
            url: https://packages.cloud.google.com/apt/doc/apt-key.gpg
            state: present

        - name: Add Kubernetes repository
          apt_repository:
            repo: "deb https://apt.kubernetes.io/ kubernetes-xenial main"
            state: present

        - name: Install kubeadm, kubelet, kubectl
          apt:
            name:
              - kubelet
              - kubeadm
              - kubectl
            state: present
            update_cache: yes

- name: Configure Monitoring and Logging
  hosts: all
  become: yes
  
  tasks:
    - name: Create monitoring directory
      file:
        path: /opt/monitoring
        state: directory
        mode: '0755'

    - name: Deploy GPU monitoring exporter
      copy:
        content: |
          #!/bin/bash
          nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv,noheader,nounits | \
          awk -F', ' '{print "gpu_temperature{gpu=\""$1"\",name=\""$2"\"} "$3"\ngpu_utilization{gpu=\""$1"\",name=\""$2"\"} "$4"\ngpu_memory_utilization{gpu=\""$1"\",name=\""$2"\"} "$5"\ngpu_memory_used_mb{gpu=\""$1"\",name=\""$2"\"} "$6"\ngpu_memory_total_mb{gpu=\""$1"\",name=\""$2"\"} "$7}'
        dest: /opt/monitoring/gpu_exporter.sh
        mode: '0755'

    - name: Create systemd service for GPU monitoring
      copy:
        content: |
          [Unit]
          Description=GPU Metrics Exporter
          After=network.target

          [Service]
          Type=simple
          ExecStart=/opt/monitoring/gpu_exporter.sh
          Restart=always

          [Install]
          WantedBy=multi-user.target
        dest: /etc/systemd/system/gpu-exporter.service

    - name: Enable and start GPU exporter
      systemd:
        name: gpu-exporter
        enabled: yes
        state: started
        daemon_reload: yes
